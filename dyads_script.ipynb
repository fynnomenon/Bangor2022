{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcd2acf-3177-4437-b7d8-6ad0448e537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94c7512-859e-4099-b53d-0c248e64c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(src):\n",
    "    num_labels,labels,stats,centroids = cv2.connectedComponentsWithStats(src,connectivity=4,ltype=None)\n",
    "    img = np.zeros((src.shape[0],src.shape[1]),np.uint8) # create a black background of all 0\n",
    "    for i in range(1,num_labels):\n",
    "        mask = labels == i # this step is to determine the location of the area through labels, assign labels information to the mask array, and then use the mask array as the index of img array\n",
    "        if stats[i][4] > 100: \n",
    "            img[mask] = 255 # areas larger than 100 shall be painted white, and areas smaller than 100 shall be painted black\n",
    "        else:\n",
    "            img[mask] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6eddaf3-32e0-4384-a1ab-0cf5c406ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(frm):\n",
    "    # convert frame to grayscale\n",
    "    frm_gray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)\n",
    "    # remove tiny particels\n",
    "    frm_out = remove_outliers(frm_gray)\n",
    "    # convert frame to black and white\n",
    "    frm_thresh = cv2.threshold(frm_out,0,255,cv2.THRESH_BINARY)[1]\n",
    "    # extract contours\n",
    "    contours,_ = cv2.findContours(frm_thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a12d99c-4250-4d80-a2a6-aea5de235a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_coords(clip, t=0):\n",
    "    x_bbox=y_bbox=w_bbox=h_bbox=0\n",
    "    # get the frame\n",
    "    frm = clip.get_frame(t)\n",
    "    # get the bounding box of the frame\n",
    "    contours = get_contours(frm)\n",
    "    # get the coordinates of the bounding box\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if w > 100 and h > 100:\n",
    "            x_bbox,y_bbox,w_bbox,h_bbox=x,y,w,h\n",
    "    \n",
    "    return x_bbox,y_bbox,w_bbox,h_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5231db6c-0e8b-4a41-a77e-61226474715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(clip): \n",
    "    clip_x, clip_y = clip.size\n",
    "    bbox = [clip_x,0,clip_y,0]\n",
    "    average_h = 740\n",
    "    \n",
    "    # iterate through frames of the video clip\n",
    "    for frm in clip.iter_frames():\n",
    "        contours = get_contours(frm)\n",
    "        \n",
    "        # iterate over contours\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            # save rectangle that contains all boundingboxes inside it\n",
    "            if x < bbox[0]:\n",
    "                bbox[0] = x \n",
    "            if x+w > bbox[1]:\n",
    "                bbox[1] = x+w \n",
    "            if y < bbox[2]:\n",
    "                bbox[2] = y \n",
    "            if y+h > bbox[3]:\n",
    "                bbox[3] = y+h \n",
    "    \n",
    "    # crop and resize the clip\n",
    "    _,_,_,clip_h = get_bbox_coords(clip)\n",
    "    scaling_factor =  average_h/clip_h\n",
    "    \n",
    "    cropped_clip = clip.fx(mpy.vfx.crop, x1=bbox[0],x2=bbox[1],y1=bbox[2],y2=bbox[3])\n",
    "    resized_clip = cropped_clip.resize(scaling_factor)\n",
    "    \n",
    "    #calculate the center of gravity of the human body in the resized clip\n",
    "    x,y,w,h = get_bbox_coords(resized_clip)\n",
    "    center = (round((2*x+w)/2),round((2*y+h)/2))\n",
    "    \n",
    "    return resized_clip, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecdd78e-a822-4b16-8839-a3ef3fb54715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dur(clip, duration):\n",
    "    rate = clip.fps\n",
    "    dur = clip.duration\n",
    "    \n",
    "    desired_rate = (rate*dur)/duration\n",
    "    scaling_factor = desired_rate/rate\n",
    "\n",
    "    # Modify the FPS\n",
    "    clip = clip.set_fps(clip.fps*scaling_factor)\n",
    "    # Apply speed up\n",
    "    clip = clip.fx(mpy.vfx.speedx,scaling_factor)\n",
    "    \n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62feb15-495b-4af9-a50a-e412de42dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_rotation(clip):\n",
    "    if clip.rotation in (90,270):\n",
    "            clip = clip.resize(clip.size[::-1])\n",
    "            clip.rotation = 0\n",
    "            \n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb3daa1-53b3-4dc2-9cb3-adf4dcc67a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gesture_combinations(pairings, is_1G=False):\n",
    "    for ind, pair in enumerate(pairings):\n",
    "        gestures_left = []\n",
    "        gestures_right = []\n",
    "        if is_1G:\n",
    "            regex_left = rf'({pair[0]})_(f01|p)'\n",
    "            regex_right = rf'({pair[1]})_(f02|n)'\n",
    "        else:\n",
    "            regex_left = rf'({pair[0]}|{pair[1]})_(f01|p)'\n",
    "            regex_right = rf'({pair[0]}|{pair[1]})_(f02|n)'\n",
    "\n",
    "        for f in files:\n",
    "            if re.search(regex_left, f):\n",
    "                gestures_left.append(f)\n",
    "            elif re.search(regex_right, f):\n",
    "                gestures_right.append(f)\n",
    "        pairings[ind] = [(left,right) for right in gestures_right for left in gestures_left]\n",
    "        \n",
    "    return pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d495ca6a-868f-4d6c-b81b-e6284ca08832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_interaction_type(left, right):\n",
    "    if len(left[26:-4]) != len(right[26:-4]):\n",
    "        return 'HR'\n",
    "    elif len(left[26:-4]) == 1:\n",
    "        return 'RR'\n",
    "    else: \n",
    "        return 'HH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0ddeb2-1724-4742-b976-501d727dd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_gesture_type(left, right):\n",
    "    if left[21:25] == 'gg00':\n",
    "        return '1G'\n",
    "    elif left[21:25] != right[21:25]:\n",
    "        return '2G_DIFF'\n",
    "    else: \n",
    "        return '2G_SAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcc93f1-d77b-45d9-a6b6-8c8fab8a8d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video DyadStimuli/2G_SAME/HR/DS_lgg09_f01_rgg09_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HR/DS_lgg09_f01_rgg09_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HR/DS_lgg09_f01_rgg09_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/RR/DS_lgg09_p_rgg09_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/RR/DS_lgg09_p_rgg09_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/RR/DS_lgg09_p_rgg09_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HR/DS_lgg19_f01_rgg09_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HR/DS_lgg19_f01_rgg09_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HR/DS_lgg19_f01_rgg09_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/RR/DS_lgg19_p_rgg09_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/RR/DS_lgg19_p_rgg09_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/RR/DS_lgg19_p_rgg09_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HH/DS_lgg09_f01_rgg19_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HH/DS_lgg09_f01_rgg19_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HH/DS_lgg09_f01_rgg19_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HR/DS_lgg09_p_rgg19_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HR/DS_lgg09_p_rgg19_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HR/DS_lgg09_p_rgg19_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/HH/DS_lgg19_f01_rgg19_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HH/DS_lgg19_f01_rgg19_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HH/DS_lgg19_f01_rgg19_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/HR/DS_lgg19_p_rgg19_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HR/DS_lgg19_p_rgg19_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HR/DS_lgg19_p_rgg19_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/HH/DS_lgg09_f01_rgg09_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HH/DS_lgg09_f01_rgg09_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HH/DS_lgg09_f01_rgg09_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/HR/DS_lgg09_p_rgg09_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HR/DS_lgg09_p_rgg09_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HR/DS_lgg09_p_rgg09_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HH/DS_lgg19_f01_rgg09_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HH/DS_lgg19_f01_rgg09_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HH/DS_lgg19_f01_rgg09_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HR/DS_lgg19_p_rgg09_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HR/DS_lgg19_p_rgg09_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HR/DS_lgg19_p_rgg09_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/HR/DS_lgg09_f01_rgg19_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/HR/DS_lgg09_f01_rgg19_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/HR/DS_lgg09_f01_rgg19_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_DIFF/RR/DS_lgg09_p_rgg19_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_DIFF/RR/DS_lgg09_p_rgg19_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_DIFF/RR/DS_lgg09_p_rgg19_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/HR/DS_lgg19_f01_rgg19_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/HR/DS_lgg19_f01_rgg19_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/HR/DS_lgg19_f01_rgg19_n.mp4\n",
      "Moviepy - Building video DyadStimuli/2G_SAME/RR/DS_lgg19_p_rgg19_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/2G_SAME/RR/DS_lgg19_p_rgg19_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/2G_SAME/RR/DS_lgg19_p_rgg19_n.mp4\n",
      "Moviepy - Building video DyadStimuli/1G/HH/DS_lgg00_f01_rgg20_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/1G/HH/DS_lgg00_f01_rgg20_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/1G/HH/DS_lgg00_f01_rgg20_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/1G/HR/DS_lgg00_p_rgg20_f02.mp4.\n",
      "Moviepy - Writing video DyadStimuli/1G/HR/DS_lgg00_p_rgg20_f02.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/1G/HR/DS_lgg00_p_rgg20_f02.mp4\n",
      "Moviepy - Building video DyadStimuli/1G/HR/DS_lgg00_f01_rgg20_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/1G/HR/DS_lgg00_f01_rgg20_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/1G/HR/DS_lgg00_f01_rgg20_n.mp4\n",
      "Moviepy - Building video DyadStimuli/1G/RR/DS_lgg00_p_rgg20_n.mp4.\n",
      "Moviepy - Writing video DyadStimuli/1G/RR/DS_lgg00_p_rgg20_n.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready DyadStimuli/1G/RR/DS_lgg00_p_rgg20_n.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "in_dir = 'IndividualStimuli'\n",
    "files = [os.path.join(in_dir, f) for f in os.listdir(in_dir)]\n",
    "\n",
    "root_dir = 'DyadStimuli'\n",
    "sub_dirs = ['1G', '2G_SAME', '2G_DIFF']\n",
    "sub_sub_dirs = ['HH','HR','RR']\n",
    "\n",
    "is_existend = os.path.exists(root_dir)\n",
    "if not is_existend:\n",
    "    os.mkdir(root_dir)\n",
    "    for sub_dir in sub_dirs:\n",
    "        path_sub_dir = os.path.join(root_dir,sub_dir)\n",
    "        os.mkdir(path_sub_dir)\n",
    "        for sub_sub_dir in sub_sub_dirs:\n",
    "            path_sub_sub_dir = os.path.join(root_dir,sub_dir,sub_sub_dir)\n",
    "            os.mkdir(path_sub_sub_dir)\n",
    "\n",
    "pairings_2G = [('gg09', 'gg19'), ('gg01', 'gg18'), ('gg10', 'gg11'), ('gg13', 'gg17'), \n",
    "                     ('gg08', 'gg20'), ('gg04', 'gg15'), ('gg02', 'gg06'), ('gg03', 'gg07'),]\n",
    "\n",
    "all_gestures_df = pd.read_excel('GesturesIndividualStimuli.xlsx', 'gestures_combinations')\n",
    "relevant_gestures_df = all_gestures_df.dropna()\n",
    "gesture_codes = relevant_gestures_df['GestureCode'].tolist()\n",
    "\n",
    "pairings_1G = []\n",
    "for i in gesture_codes[1:]:\n",
    "    single_gesture = ('gg00', i)\n",
    "    pairings_1G.append(single_gesture)\n",
    "\n",
    "combinations_2G = create_gesture_combinations(pairings_2G)\n",
    "combinations_1G = create_gesture_combinations(pairings_1G, True)\n",
    "all_combinations = combinations_2G + combinations_1G\n",
    "\n",
    "for cnt,comb in enumerate(all_combinations[::len(all_combinations)-1]):\n",
    "    for gestures in comb:\n",
    "        # Determine the interaction and gesture type of the dyad stimuli to be created\n",
    "        interaction_type = determine_interaction_type(gestures[0],gestures[1])\n",
    "        gesture_type = determine_gesture_type(gestures[0],gestures[1])\n",
    "        \n",
    "        # Load the video files of the individual stimuli to be combined into a dyad\n",
    "        gesture_left = mpy.VideoFileClip(gestures[0],has_mask=True)\n",
    "        gesture_right = mpy.VideoFileClip(gestures[1],has_mask=True).fx(mpy.vfx.mirror_x)\n",
    "\n",
    "        # Workaround for the moviepy bug causing videos with rotation metadata to be stretched\n",
    "        gesture_left = fix_rotation(gesture_left)\n",
    "        gesture_right = fix_rotation(gesture_right)\n",
    "\n",
    "        # Transform the individual stimuli files\n",
    "        gesture_left, center_left = crop_and_resize(gesture_left)\n",
    "        gesture_right, center_right = crop_and_resize(gesture_right)\n",
    "\n",
    "        # Speed up or slow down video to 3sec\n",
    "        duration = 3\n",
    "        gesture_right = change_dur(gesture_right,duration)\n",
    "        gesture_left = change_dur(gesture_left,duration)\n",
    "\n",
    "        # Load the background image\n",
    "        background = mpy.ImageClip('background_dyads.png',duration=duration)\n",
    "\n",
    "        # Create the video composition\n",
    "        dyad = mpy.CompositeVideoClip([background, \n",
    "                                       gesture_left.set_position((660-center_left[0],background.size[1]-gesture_left.size[1]-170)), \n",
    "                                       gesture_right.set_position((1260-center_right[0],background.size[1]-gesture_right.size[1]-170))\n",
    "                                      ])\n",
    "        # Make the video grayscale\n",
    "        dyad = dyad.fx(mpy.vfx.blackwhite)\n",
    "\n",
    "        # Write the output video file\n",
    "        out_path = os.path.join(root_dir,gesture_type,interaction_type,f'DS_l{gestures[0][21:-4]}_r{gestures[1][21:-4]}.mp4')\n",
    "        dyad.write_videofile(out_path,fps=25,audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl4nlp]",
   "language": "python",
   "name": "conda-env-dl4nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
