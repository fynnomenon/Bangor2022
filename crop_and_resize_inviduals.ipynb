{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41455ae3-534e-4066-b96b-84462c39e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import moviepy.editor as mpy\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.contrib import tzip\n",
    "from os import mkdir, listdir\n",
    "from os.path import exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b28bc0-8a90-4cb0-9274-fd7377edcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(src):\n",
    "    num_labels,labels,stats,centroids = cv2.connectedComponentsWithStats(src,connectivity=4,ltype=None)\n",
    "    img = np.zeros((src.shape[0],src.shape[1]),np.uint8) # create a black background of all 0\n",
    "    for i in range(1,num_labels):\n",
    "        mask = labels == i # this step is to determine the location of the area through labels, assign labels information to the mask array, and then use the mask array as the index of img array\n",
    "        if stats[i][4] > 100: \n",
    "            img[mask] = 255 # areas larger than 100 shall be painted white, and areas smaller than 100 shall be painted black\n",
    "        else:\n",
    "            img[mask] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8685352f-d2fc-4dde-8d4f-444b49abfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(frm):\n",
    "    # convert frame to grayscale\n",
    "    frm_gray = cv2.cvtColor(frm, cv2.COLOR_BGR2GRAY)\n",
    "    # remove tiny particels\n",
    "    frm_out = remove_outliers(frm_gray)\n",
    "    # convert frame to black and white\n",
    "    frm_thresh = cv2.threshold(frm_out,0,255,cv2.THRESH_BINARY)[1]\n",
    "    # extract contours\n",
    "    contours,_ = cv2.findContours(frm_thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c97267-3a2a-4dc2-bfa7-5b5b33653cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_coords(clip, t=0):\n",
    "    x_bbox=y_bbox=w_bbox=h_bbox=0\n",
    "    # get the frame\n",
    "    frm = clip.get_frame(t)\n",
    "    # get the bounding box of the frame\n",
    "    contours = get_contours(frm)\n",
    "    # get the coordinates of the bounding box\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if w > 100 and h > 100: # only consider rectangles of relevant size\n",
    "            x_bbox,y_bbox,w_bbox,h_bbox=x,y,w,h\n",
    "    \n",
    "    return x_bbox,y_bbox,w_bbox,h_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8feca0c-9b13-4b34-a348-8070b373ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(clip): \n",
    "    clip_x, clip_y = clip.size\n",
    "    bbox = [clip_x,0,clip_y,0]\n",
    "    average_h = 740\n",
    "    \n",
    "    # iterate through frames of the video clip\n",
    "    for frm in clip.iter_frames():\n",
    "        contours = get_contours(frm)\n",
    "        \n",
    "        # iterate over contours\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            # save rectangle that contains all boundingboxes inside it\n",
    "            if x < bbox[0]:\n",
    "                bbox[0] = x \n",
    "            if x+w > bbox[1]:\n",
    "                bbox[1] = x+w \n",
    "            if y < bbox[2]:\n",
    "                bbox[2] = y \n",
    "            if y+h > bbox[3]:\n",
    "                bbox[3] = y+h \n",
    "    \n",
    "    # crop and resize the clip\n",
    "    _,_,_,clip_h = get_bbox_coords(clip)\n",
    "    scaling_factor =  average_h/clip_h\n",
    "    \n",
    "    cropped_clip = clip.fx(mpy.vfx.crop, x1=bbox[0],x2=bbox[1],y1=bbox[2],y2=bbox[3])\n",
    "    resized_clip = cropped_clip.resize(scaling_factor)\n",
    "    \n",
    "    return resized_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5c8abd-b103-45e8-a7fc-e5afd4eed263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_rotation(clip):\n",
    "    # Workaround for the moviepy bug causing videos with rotation metadata to be stretched\n",
    "    if clip.rotation in (90,270):\n",
    "            clip = clip.resize(clip.size[::-1])\n",
    "            clip.rotation = 0\n",
    "            \n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5677a514-e36f-4e60-afcf-bbc2e9b2db5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f45ee53056545dd981b3cadd5aa2c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_dir = 'IndividualStimuli'\n",
    "file_names = listdir(in_dir)\n",
    "file_paths = [join(in_dir, f) for f in file_names]\n",
    "\n",
    "out_dir = 'IndividualStimuliCleaned'\n",
    "is_existend = exists(out_dir) \n",
    "if not is_existend: # create the folder structure of the output directory\n",
    "    mkdir(out_dir)\n",
    "\n",
    "seq_dir = 'ImageSequences'\n",
    "is_existend = exists(seq_dir) \n",
    "if not is_existend: # create a folder dor the image sequences\n",
    "    mkdir(seq_dir)    \n",
    "\n",
    "for f_name,f_path in tzip(file_names,file_paths):\n",
    "    # load the video files of the individual stimuli to be cleaned\n",
    "    clip = mpy.VideoFileClip(f_path, has_mask=True)\n",
    "    # Workaround for the moviepy bug causing videos with rotation metadata to be stretched\n",
    "    temp_clip = fix_rotation(clip)\n",
    "    # transform the individual stimuli files\n",
    "    cleaned_clip = crop_and_resize(temp_clip)\n",
    "    \n",
    "    # Workaround for the moviepy bug that write_videofile() cannot export a video clip with an alpha channel\n",
    "    img_seq_path = join(seq_dir, f_name[:-4])\n",
    "    mkdir(img_seq_path)\n",
    "    fps = cleaned_clip.fps\n",
    "    cleaned_clip.write_images_sequence(f'{img_seq_path}/frame%04d.png', fps=fps, withmask=True, verbose=False, logger=None) # create image sequence of cleaned video\n",
    "    \n",
    "    command = f'ffmpeg -i {img_seq_path}/frame%4d.png -framerate {fps} -pix_fmt yuva444p10le -vcodec prores_ks -threads 6 {out_dir}/{f_name}' # create transparent video out of image sequence\n",
    "    subprocess.call(command, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl4nlp]",
   "language": "python",
   "name": "conda-env-dl4nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
